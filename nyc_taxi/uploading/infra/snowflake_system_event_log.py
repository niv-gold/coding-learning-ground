from __future__ import annotations
from snowflake import connector
from nyc_taxi.uploading.core.models import FileIdentity
from nyc_taxi.uploading.core.ports import LoadLogRepository
from nyc_taxi.uploading.config.settings import SnowflakeConfig
from nyc_taxi.uploading.infra.local_finder import LocalFileFinder
import uuid
from pathlib import Path
from datetime import datetime
import json 
from dotenv import load_dotenv

class SnowflakeLoadLogRepository(LoadLogRepository):
    """
    Uses SYSTEM_EVENT_LOG table to:
    - detect already loaded files (entity_type='FILE', event_type='INGEST', status='SUCCESS')
    - write success/failure events for each file
    """

    def __init__(self, conn_params: dict):
        self.conn_params = conn_params
        self.log_table = conn_params["log_table"]
        self.log_schema = conn_params["log_schema"]

    def _connect(self):
        return connector.connect(**self.conn_params)

    def already_loaded(self, file_keys: list[str])-> set[str]:        
        """
            entity_id - holds the stable_key() output: {self.name}|{self.size_byte}|{int(self.modified_time.timestamp())}
                        (Exaple: taxi_zone_lookup.csv|12345|1767285799)
        """
        
        if not file_keys:
            return set()

        # Use VALUES binding pattern to avoid unsafe string concat
        sql_place_holders = ", ".join(['(%s)'] * len(file_keys))
        sql = f"""
            SELECT distinct entity_id
            FROM {self.log_schema}.{self.log_table}
            WHERE entity_id IN (SELECT column1 FROM VALUES {sql_place_holders})
                AND entity_type = 'FILE'
                AND event_type  = 'INGEST'
                AND status = 'SUCCESS'
        """

        with self._connect() as conn:
            with conn.cursor() as cur:
                cur.execute(sql, file_keys)
                rows = cur.fetchall()
        return { file[0] for file in rows }        

    def _insert_event(self, *, event_id: str, run_id: str, event_level: str, event_type: str, component: str, entity_type: str, 
                      entity_id: str, status: str, message: str, error_code: str | None, error_details: str | None, metadata: dict)-> None:
        """
        Insert a row into SYSTEM_EVENT_LOG.
        """
        # We store metadata as VARIANT; easiest is to pass JSON string and PARSE_JSON in SQL.
        metadata_json = json.dumps(metadata or {}, allow_nan=False, separators=(",", ":"), ensure_ascii=False)

        sql = f"""
            INSERT INTO {self.log_schema}.{self.log_table} (
                event_id,
                run_id,
                event_timestamp,
                event_level,
                event_type,
                component,
                entity_type,
                entity_id,
                status,
                message,
                error_code,
                error_details,
                metadata
            ) 
            SELECT
            %s, %s, CURRENT_TIMESTAMP(),
                %s, %s, %s,
                %s, %s,
                %s, %s,
                %s, %s,
                PARSE_JSON(%s)            
            """
        
        params = (
            event_id, run_id,
            event_level, event_type, component,
            entity_type, entity_id,
            status, message,
            error_code, error_details,
            metadata_json
        )

        with self._connect() as conn:
            with conn.cursor() as cur:
                cur.execute(sql, params)

    def log_run_started(self, *, event_id: str, run_id: str, component: str, message: str, metadata: dict | None = None) -> None:
        self._insert_event(
            event_id=event_id,
            run_id=run_id,
            event_level="INFO",
            event_type="RUN",
            component=component,
            entity_type="RUN",
            entity_id=run_id,
            status="STARTED",
            message=message,
            error_code=None,
            error_details=None,
            metadata=metadata,
        )

    def log_run_finished(self, *, event_id: str, run_id: str, component: str, status: str, message: str, metadata: dict | None = None) -> None:
        # status should be "SUCCESS" or "FAILURE" for the overall run
        self._insert_event(
            event_id=event_id,
            run_id=run_id,
            event_level="INFO" if status == "SUCCESS" else "ERROR",
            event_type="RUN",
            component=component,
            entity_type="RUN",
            entity_id=run_id,
            status=status,
            message=message,
            error_code=None,
            error_details=None,
            metadata=metadata,
        )

    def log_success(self, run_id: str, entity_type: str, entity_id: str, component: str, message: str, metadata: dict)-> None:
        # event_id should be generated by caller (pipeline) so it can be correlated if needed
        # but to keep the interface simple, we can generate it here if you prefer.
        raise NotImplementedError("Use log_event_success(...) below or modify to generate event_id")
    
    def log_failure(self, run_id: str, entity_type: str, entity_id: str, component: str, message: str, error_details: str, metadata: dict)-> None:
        raise NotImplementedError("Use log_event_failure(...) below or modify to generate event_id")

    # Practical methods â€” explicitly include event_id + standard fields
    def log_ingest_success(self, *, event_id: str, run_id: str, component: str, entity_id: str, message: str, metadata: dict)-> None:
        self._insert_event(
            event_id= event_id,
            run_id= run_id,                
            event_level= 'INFO',
            event_type= "INGEST",
            component= component,
            entity_type= 'FILE',
            entity_id= entity_id,
            status= 'SUCCESS',
            message= message,
            error_code= None,
            error_details= None,
            metadata= metadata
        )

    def log_ingest_failure(self, *, event_id: str, run_id: str, component: str, entity_id: str, message: str, error_details: str, metadata: dict)-> None:
        self._insert_event(
            event_id= event_id,
            run_id= run_id,                
            event_level= 'INFO',
            event_type= "INGEST",
            component= component,
            entity_type= 'FILE',
            entity_id= entity_id,
            status= 'FAILURE',
            message= message,
            error_code= None,
            error_details= error_details,
            metadata= metadata
        )

    def log_run_event(self, *, event_id: str, run_id: str, component: str, entity_id: str, message: str, metadata: dict)-> None:
        self._insert_event(
            event_id= event_id,
            run_id= run_id,                
            event_level= 'RUN',
            event_type= "PIPELINE",
            component= component,
            entity_type= 'RUN',
            entity_id= entity_id,
            status= 'SUCCESS',
            message= message,
            error_code= None,
            error_details= None,
            metadata= metadata
        )

if __name__=='__main__':
    load_dotenv()

    path = Path('/home/niv/home/GitHubeRepos/my_codes/nyc_taxi/uploading/app/data_files')
    files = LocalFileFinder(path).list_files()
    list_files_stable_key = [file.stable_key for file in files]

    snowflake_config = SnowflakeConfig.from_env().to_connector_kwarg()
    sn_inst = SnowflakeLoadLogRepository(conn_params=snowflake_config)

    sn_inst._insert_event(event_id=str(uuid.uuid4()), run_id=str(uuid.uuid4()), event_level='INFO', event_type='RUN', component='INGESTION', entity_type='File',
                          entity_id='taxi_zone_lookup.csv|12345|1767285799', status='SUCCESS', message='The log is A OK', error_code=None, error_details=None,
                          metadata={"stage": "test_step"})
    
    sn_inst.log_ingest_success(event_id=str(uuid.uuid4()), run_id=str(uuid.uuid4()),component='INGESTION', entity_id='taxi_zone_lookup.csv|12345|1767285799', 
                                message='sn_inst.log_ingest_success', metadata={"stage": "test_step_1"})
    
    sn_inst.log_ingest_failure(event_id=str(uuid.uuid4()), run_id=str(uuid.uuid4()),component='INGESTION', entity_id='taxi_zone_lookup.csv|12345|1767285799', 
                                message='sn_inst.log_ingest_success', error_details='Error as acured!!!' ,metadata={"stage": "test_step_1"})
    
